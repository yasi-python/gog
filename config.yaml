# v2config-manager — production-ready config
# Place this file at the repository root as: config.yaml

service:
  http_listen: ":8080"                 # REST API + Prometheus metrics
  metrics_path: "/metrics"
  healthz_path: "/healthz"
  dry_run: true                        # keep true for the first weeks; set to false after validation
  log_level: "info"                    # debug|info|warn|error
  data_dir: "data"                     # BoltDB location (auto-created)
  snapshots_dir: "snapshots"           # snapshots (auto-created before any deletion)
  snapshot_retention_days: 30
  max_deletions_per_day: 50            # safety throttle
  concurrency: 100                     # worker pool for probing
  rate_limit_per_target_per_minute: 10 # anti-ban throttling
  reprobe_schedule_seconds: 300        # background re-probe interval (5m)

subscriptions:
  # Your provided subscription sources (merged + deduped automatically)
  sources:
    - "https://raw.githubusercontent.com/yasi-python/PSGd/refs/heads/main/output/base64/mix"
    - "https://raw.githubusercontent.com/yasi-python/PSGS/refs/heads/main/subscriptions/xray/base64/mix"
    - "https://raw.githubusercontent.com/yasi-python/vip/refs/heads/master/sub/sub_merge_base64.txt"
    - "https://raw.githubusercontent.com/barry-far/V2ray-Config/refs/heads/main/All_Configs_base64_Sub.txt"
    - "https://raw.githubusercontent.com/mahdibland/V2RayAggregator/refs/heads/master/sub/sub_merge_base64.txt"
    - "https://raw.githubusercontent.com/SoliSpirit/v2ray-configs/refs/heads/main/all_configs.txt"
    - "https://raw.githubusercontent.com/Epodonios/v2ray-configs/refs/heads/main/All_Configs_base64_Sub.txt"
    - "https://raw.githubusercontent.com/Danialsamadi/v2go/refs/heads/main/All_Configs_Sub.txt"
  fetch_interval_seconds: 1800         # refresh/merge every 30m
  per_source_limit: 2000               # cap per source to avoid flooding
  merged_limit: 2000                   # overall cap after dedupe
  outputs:                             # final outputs (paths exist locally; commit only if you want)
    plain_path: "output/merged_nodes.txt"
    base64_path: "output/merged_sub_base64.txt"

probe:
  timeout_ms: 5000                     # per-probe timeout (5s)
  retries: 2                           # retry count with backoff
  backoff_initial_ms: 300
  backoff_max_ms: 3000
  http_probe_paths: ["/", "/health", "/"]   # if ws/path present, try HTTP GET in-tunnel
  prefer_http_if_ws_or_path: true

# Multi-origin probing: local + (optional) remote agents
origins:
  - name: "local"
    type: "local"
    weight: 1

  # Example agents (optional) — run cmd/agent on remote servers, then uncomment:
  # - name: "edge-eu"
  #   type: "agent"
  #   url: "http://eu-your-agent:8081"
  #   token: "CHANGE_ME"
  #   weight: 1
  # - name: "edge-us"
  #   type: "agent"
  #   url: "http://us-your-agent:8081"
  #   token: "CHANGE_ME"
  #   weight: 1

decision:
  min_attempts_for_decision: 200       # require enough evidence
  decision_confidence_z: 2.575829      # ~99% confidence
  quarantine_consecutive_failures: 10  # quarantine after 10 consecutive fails
  quarantine_rechecks: ["1h","6h","24h","48h"]
  delete_lower_bound_threshold: 0.995  # delete only if LB(fail_rate) ≥ 0.995

security:
  allow_delete: false                  # keep false until you are confident; set true for real deletions
  blacklist_ips: []                    # optional: add IPs to watch/deny

api:
  rate_limit_per_minute: 120           # API rate limit (global)